# Thresholds for positive class (absolutes top k and top k %)
score_thresholds:
    rank_abs: [150, 300]
    rank_pct: [1.0, 2.0, 5.0, 10.0 ]

#available options: "predefined", "majority" and "min_metric"
ref_groups_method: "predefined"

# if "predefined" is selected, you need to provide the column:value pairs to be used as reference
ref_groups:
  "attribute_1": "<0.30"

# fairness threshold to be used for assessing fairness
fairness_threshold: 0.8

# available fairness_measeure "Impact Parity", "Statistical Parity", "FPR Parity", "FDR Parity", "FNR Parity", "FOR Parity"
fairness_measures: ["FPR Parity", "FNR Parity"]

#db:
  # Database access credentials, the input query to get the input table and schema to write results:
    #db_credentials:
        #host: your_host
        #database: your_db
        #user: your_user
        #password: your_pass
        #port: 5432


    # the input query should return a table with score, label_value columns and then each attribute you want to use for bias analysis
    #input_query: "select id, score, label_value, attribute_1, attribute_2 from results.predictions left join ..."

    # the output schema is optional, default=public
    #output_schema: results
